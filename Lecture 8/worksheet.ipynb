{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a random network (with N>10.000 nodes) using the Barabasi-Albert model, and create a meaningful plot of the degree distribution!\n",
    "Once the network is ready, gradually swap edges between nodes and track the change of the network topology by looking at the changes in the degree distribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Construct a network from referencing webpages! E.g. choose webpage of the Dept. of Complex Systems as the first node of the network and create new nodes and links from the \"href\" references! Make a visualisation of the growing network as the diameter of the network increases! (Diameter of a graph is the maximal distance between the nodes of the network. The distance between two nodes is measured by the number of steps along the shortest path connecting the node pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. During reconnecting (swapping) links between nodes, usually we need a constant quantity, which does not change during the swapping of links. E.g. one can fix the degree distribution by setting a constraint at each node, how many incoming/outgoing connection it must have. Create small networks (N<50 nodes), which are randomized with swapping the links constraining the degrees of each node. By creating a visual representation of the network track the changes of swapping of the links! Show some examples, where this type of randomization does not change the topology of the network at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.1',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a BA-graph using networkx with N > 10.000 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1.5e5    # Number of nodes\n",
    "m = 1        # Number of new edges in each step\n",
    "G = nx.barabasi_albert_graph(n=n, m=m, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoints of edges\n",
    "edges_list = list(G.edges)\n",
    "\n",
    "# Degrees of nodes\n",
    "degree_list = list(G.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect only the degree values of nodes\n",
    "degree_values = np.zeros(int(n))\n",
    "for i, node in enumerate(degree_list):\n",
    "    degree_values[i] = node[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of node degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 1\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*15, nrows*8))\n",
    "\n",
    "axislabelsize = 22\n",
    "axisticksize = 18\n",
    "\n",
    "hist, bins = np.histogram(a=degree_values, bins=50, density=True)\n",
    "# Using log-log axis for a better view\n",
    "axes.loglog(bins[:-1], hist,\n",
    "            c='tab:red', marker='o', ms=10, lw=0,\n",
    "            zorder=3)\n",
    "axes.loglog(bins[:-1], hist,\n",
    "            c='tab:green', lw=3, ls='--')\n",
    "\n",
    "axes.set_xlabel('Node ranks', fontsize=axislabelsize)\n",
    "axes.set_ylabel('Dist. of node ranks', fontsize=axislabelsize)\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degrees of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 1\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*15, nrows*8))\n",
    "\n",
    "axislabelsize = 22\n",
    "axisticksize = 18\n",
    "radius = 3\n",
    "\n",
    "axes.scatter(range(int(n)), degree_values,\n",
    "             s=radius**2, alpha=0.4)\n",
    "\n",
    "# Using log y-axis for a better view\n",
    "#axes.set_xscale('log')\n",
    "axes.set_yscale('log')\n",
    "\n",
    "axes.set_xlabel('Index of nodes', fontsize=axislabelsize)\n",
    "axes.set_ylabel('Node ranks', fontsize=axislabelsize)\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collect href links from webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Eötvös Loránd Tudományegyetem -- Wikipedia page\n",
    "\n",
    "For the first try, I've used the hungarian Wikipedia article on `Eötvös Loránd Tudományegyetem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Wikipedia all article references starts with simply the `/wiki/*` path. We should sort out all other references, eg. those starting with `http://` or `https://`, since those are only off-wikipedia references/citations/other junk. Also we need to sort out references starting with `#` and with the `/w/` tag and other miscellaneous hrefs, like those which contains `:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_start = 'https://hu.wikipedia.org'\n",
    "hrefs_out = './hrefs/wikipedia_hrefs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_wiki_hrefs(url):\n",
    "    \n",
    "    html_page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    hrefs = []\n",
    "    for link in soup.findAll('a'):\n",
    "        tmp_link = link.get('href')\n",
    "        if tmp_link is not None:\n",
    "            if(tmp_link[:6] == '/wiki/'\n",
    "               and\n",
    "               ':' not in tmp_link):\n",
    "                hrefs.append(wiki_start + tmp_link)\n",
    "\n",
    "    # Sort out references which are listed multiple times\n",
    "    return list(np.unique(hrefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'https://hu.wikipedia.org/wiki/E%C3%B6tv%C3%B6s_Lor%C3%A1nd_Tudom%C3%A1nyegyetem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_0 = sort_wiki_hrefs(url=start_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hrefs_out + 'hrefs_0', 'wb') as fp:\n",
    "    pickle.dump(hrefs_0, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of edges in the starting layer is {0}.'.format(len(hrefs_0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_1 = [sort_wiki_hrefs(url=url) for url in hrefs_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hrefs_out + 'hrefs_1', 'wb') as fp:\n",
    "    pickle.dump(hrefs_1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for n in hrefs_1:\n",
    "    count += len(n)\n",
    "\n",
    "print('Number of edges after the first layer is {0}.'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even after the first layer, there are 53284 differnt edges in the graph if we start on a Wikipedia page, which makes this problem very hard to solve. For a good visualization we need at least 4-5 layers of references, so I have to choose another starting URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) ELTE webpage -- https://www.elte.hu/\n",
    "\n",
    "For the second attempt I've tried using https://www.elte.hu/ as my starting URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elte_start = 'https://www.elte.hu/'\n",
    "hrefs_out = './hrefs/elte_hrefs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_elte_hrefs(url):\n",
    "    \n",
    "    html_page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    hrefs = []\n",
    "    for link in soup.findAll('a'):\n",
    "        tmp_link = link.get('href')\n",
    "        if tmp_link is not None:\n",
    "            print(tmp_link)\n",
    "            print(tmp_link[0])\n",
    "            if tmp_link[0] != '#':\n",
    "                if 'http' not in tmp_link:\n",
    "                    hrefs.append(elte_start + tmp_link)\n",
    "                else:\n",
    "                    hrefs.append(tmp_link)\n",
    "\n",
    "    # Sort out references which are listed multiple times\n",
    "    return list(np.unique(hrefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'https://www.elte.hu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_0 = sort_elte_hrefs(url=start_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hrefs_out + 'hrefs_0', 'wb') as fp:\n",
    "    pickle.dump(hrefs_0, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of edges in the starting layer is {0}.'.format(len(hrefs_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_elte_hrefs(url='https://www.elte.hu/allaspalyazatok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_1 = [sort_elte_hrefs(url=url) for url in hrefs_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hrefs_out + 'hrefs_1', 'wb') as fp:\n",
    "    pickle.dump(hrefs_1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for n in hrefs_1:\n",
    "    count += len(n)\n",
    "\n",
    "print('Number of edges after the first layer is {0}.'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
