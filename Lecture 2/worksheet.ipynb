{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction into handling geographical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[John Snow](https://en.wikipedia.org/wiki/John_Snow) was an English physician, who was first to trace the source of a cholera outbreak in London's Soho district in 1854 using data visualization. In the following exercises, we are going to reconstruct the map of Snow with modern tools and explore some ideas of geographic data analysis.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/Snow-cholera-map-1.jpg\" width=\"400px\"></img>\n",
    "\n",
    "Though there is a whole [R library](https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Snow.pumps.html) dedicated to this dataset, we would like R users to also build the solutions (e.g. Voronoi cells) from scratch.\n",
    "\n",
    "Further reading:\n",
    "* https://en.wikipedia.org/wiki/1854_Broad_Street_cholera_outbreak\n",
    "* https://www1.udel.edu/johnmack/frec682/cholera/cholera2.html\n",
    "* https://www.theguardian.com/news/datablog/interactive/2013/mar/15/cholera-map-john-snow-recreated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapefile that will be used in these exercises are located at http://donboyes.com/2011/10/14/john-snow-and-serendipity/, but they are already downloaded into the shapes directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib and Seaborn parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control chars for bold text in print() statements\n",
    "b_on = '\\033[1m'\n",
    "b_off = '\\033[0m'\n",
    "\n",
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.1',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Load the death and the pump dataset into a tabular format! Have a look at the dataset's structure! The pump dataset contains the locations of wells, that were used to obtain water for drinking, cooking etc.\n",
    "\n",
    "*The format of the files is called [shapefile](https://en.wikipedia.org/wiki/Shapefile), which is a format that is easily readable by the most common GIS (Geographic Information System) softwares. Shapefiles consist of many files, some of which store the geographic information, some the coordinate system description, some the additional attributes of the geographical objects. [geopandas](http://geopandas.org/) is able to read shapefiles natively into its base class GeoDataFrame, which has a similar API to that of `pandas` `DataFrames`. This is convenient, because we can use all of our previous knowledge of `pandas`.*\n",
    "\n",
    "*It is sometimes worth to have a look at a shapefile's content quickly. For Linux, [QGIS](https://www.qgis.org/en/site/about/index.html) is a powerful free GIS system, try it at home!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read random shapefiles\n",
    "deaths = gpd.read_file('/home/workdir/followingjohnsnow/shapes/deaths_gcs.shp')\n",
    "pumps = gpd.read_file('/home/workdir/followingjohnsnow/shapes/pumps_gcs.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The original datafiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(deaths.head())\n",
    "display(pumps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Extract the latitudes and the longitudes for each row in both datasets as additional columns!\n",
    "\n",
    "*In a `GeoDataFrame`, the `geometry` column contains geometry objects from the [`shapely`](https://toblerity.org/shapely/index.html) library. These objects have coordinate attributes, that is where latitude and longitude values are stored.*\n",
    "\n",
    "The 'X' and 'Y' columns are coordinates in an arbitrary coordinate system and usually not part of a *shp* file. \n",
    "\n",
    "Project your points into a coordinate system where you can measure real distances (using e.g. `pyproj`), then create a meaningul visualization of the data!\n",
    "\n",
    "*It is crucial to use the appropriate coordinate system for your purposes. For this exercise, the spherical coordinate system of lon, lat values is not convenient, since we cannot calculate distances in meters as easily as we would in a Cartesian coordinate system. Because of the Earth's shape, most projections distort distances at certain latitudes and longitudes.*\n",
    "\n",
    "*In GIS, different coordinate systems are called CRS (Coordinate Reference System), and have patented codes that define the origin, the projection etc. The usual lon, lat pairs are called the WGS84 system (you will need to find its epsg code first). A good choice for a Cartesian system is for example the Pseudo-Mercator projection. The `pyproj` library is especially lightweight to use in Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append additional Lat-Long columns to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional Lat-Long columns to deaths and pumps GeoDFs\n",
    "# Use the `geometry` column to get coordinate values\n",
    "pumps['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The type of the entries are `shapely.geometry.point.Point`\n",
    "type(pumps['geometry'][0])\n",
    "\n",
    "# They contain the coordinates in the following format\n",
    "test_pump = np.random.choice(pumps['geometry'])\n",
    "print('Long-Lat coordinates of the test pump respeectively:', test_pump.coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append death and pump coordinates as new columns to the GeoDFs\n",
    "deaths['lat'] = [xy.coords[0][1] for xy in deaths['geometry']]\n",
    "deaths['long'] = [xy.coords[0][0] for xy in deaths['geometry']]\n",
    "\n",
    "pumps['lat'] = [xy.coords[0][1] for xy in pumps['geometry']]\n",
    "pumps['long'] = [xy.coords[0][0] for xy in pumps['geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The modified datafiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(deaths.head())\n",
    "display(pumps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set CRS on GeoDF points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since 2018 GeoPandas has its own to_crs() method to easily set\n",
    "# an arbitrary CRS on shapefile points, thus we may not use `pyproj`\n",
    "# This method directly projects spherical coordinates to Pseudo-Mercator projection\n",
    "#\n",
    "# The data are given in the WGS 84 metric, but we should convert it to a more\n",
    "# convenient projection, like Web Mercator/WGS 84 Pseudo-Mercator\n",
    "# The Web Mercator's EPSG code is 3857, which could be found here:\n",
    "# https://spatialreference.org/ref/sr-org/7483/\n",
    "deaths_proj = deaths['geometry'].to_crs({'init': 'epsg:3857'})\n",
    "pumps_proj = pumps['geometry'].to_crs({'init': 'epsg:3857'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add them to the `deaths` and `pumps` GeoDFs\n",
    "deaths['lat_proj'] = [death.coords[0][1] for death in deaths_proj]\n",
    "deaths['long_proj'] = [death.coords[0][0] for death in deaths_proj]\n",
    "\n",
    "pumps['lat_proj'] = [pump.coords[0][1] for pump in pumps_proj]\n",
    "pumps['long_proj'] = [pump.coords[0][0] for pump in pumps_proj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The newly modified datafiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(deaths.head())\n",
    "display(pumps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This projection outputs coordinates in metres. However the scale of these values are farly unconvenient, and may be rescaled. Thus, we place the center of the coordinate system into the mean of the projected 2D values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_c = np.mean([np.mean(deaths.lat_proj), np.mean(pumps.lat_proj)])\n",
    "long_c = np.mean([np.mean(deaths.long_proj), np.mean(pumps.long_proj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths['lat_proj_rs'] = deaths.lat_proj - lat_c\n",
    "deaths['long_proj_rs'] = deaths.long_proj - long_c\n",
    "\n",
    "pumps['lat_proj_rs'] = pumps.lat_proj - lat_c\n",
    "pumps['long_proj_rs'] = pumps.long_proj - long_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The final, modified datafiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(deaths.head())\n",
    "display(pumps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "How many deaths were within a given radius around the wells? Test for a series of radiuses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances of all deaths from all pumps individually\n",
    "# dist : dictionary \n",
    "#   - shape : N keys, M values per keys\n",
    "#     N : number of pumps\n",
    "#     M : total number of deaths\n",
    "dist = {}\n",
    "for _, p in pumps.iterrows():\n",
    "    # Use Euclidean distance\n",
    "    dist[p.OBJECTID] = sorted([np.sqrt((p.lat_proj_rs - d.lat_proj_rs)**2 + (p.long_proj_rs - d.long_proj_rs)**2) \\\n",
    "                               for _, d in deaths.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the closest and furthest death from any pump\n",
    "min_r = np.min([dist[i] for i in range(1, len(dist)+1)])\n",
    "max_r = np.max([dist[i] for i in range(1, len(dist)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "radius = np.linspace(min_r, max_r, 1000)\n",
    "\n",
    "# Count number of death in specific radius\n",
    "dist_count = {}\n",
    "for idx, dists in dist.items():\n",
    "    dist_count[idx] = [np.sum([d < r for d in dists]) for r in radius]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose distinct colors for the dist. datasets of different pumps\n",
    "def pump_color(pumps, cmap=cm.jet_r):\n",
    "\n",
    "    m = scipy.interpolate.interp1d([min(pumps), max(pumps)], [0,1])\n",
    "    \n",
    "    colors = {p: cmap(m(p)) for p in pumps}\n",
    "    \n",
    "    colors_arr = []\n",
    "    for d in pumps:\n",
    "        colors_arr.append(colors[d])\n",
    "        \n",
    "    return np.array(colors_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(14,8))\n",
    "\n",
    "axislabelsize = 22\n",
    "axisticksize = 15\n",
    "axislegendsize = 16\n",
    "\n",
    "colors = pump_color(pumps.OBJECTID.values)\n",
    "for idx, dists in dist_count.items():\n",
    "    axes.plot(radius, dists, label='Pump #{0}'.format(idx),\n",
    "              c=colors[idx-1], lw=3, alpha=0.7)\n",
    "\n",
    "axes.set_xlabel('Distance from pump [m]', fontsize=axislabelsize)\n",
    "axes.set_ylabel('Number of deaths', fontsize=axislabelsize)\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put both the deaths and the pumps on a zoomable map that has a base layer from a tile server different from that of the default settings of your chosen method. Set the appropriate map center and zoom level. Use different markers for the deaths and the pumps datasets.\n",
    "\n",
    "*Try folium in Python, or Leaflet in R or JS. Display the map here in the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Folium map object\n",
    "# Here, we should use the original spherical coordinates!\n",
    "# --------\n",
    "# Center the map in a spherical coordinate system on the\n",
    "# mean of the deaths' and pumps' location\n",
    "lat_c = np.mean([np.mean(deaths.lat), np.mean(pumps.lat)])\n",
    "long_c = np.mean([np.mean(deaths.long), np.mean(pumps.long)])\n",
    "\n",
    "# Since we should use a different tile server, than the default 'OpenStreetMap',\n",
    "# here I am using CartoDB's Positron map style, because this resembles mostly\n",
    "# at the famous map of John Snow, inserted into the head of the notebook above\n",
    "#\n",
    "# In this variable name, JS stands for John Snow, and absolutely not for JavaScript\n",
    "JS_map = folium.Map(location=[lat_c, long_c], zoom_start=16, tiles='CartoDB Positron')\n",
    "\n",
    "# Mark deaths on map\n",
    "for _, death in deaths.iterrows():\n",
    "    marker = folium.Marker(location=[death.lat, death.long],\n",
    "                           icon=folium.Icon(icon='ambulance', prefix='fa', color='black'),\n",
    "                           popup='Death #{0}'.format(death.OBJECTID))\n",
    "    marker.add_to(JS_map)\n",
    "\n",
    "# Mark pumps on map\n",
    "for _, pump in pumps.iterrows():\n",
    "    marker = folium.Marker(location=[pump.lat, pump.long],\n",
    "                           icon=folium.Icon(icon='glyphicon-tint', color='blue'),\n",
    "                           popup='Pump #{0}'.format(pump.OBJECTID))\n",
    "    marker.add_to(JS_map)\n",
    "\n",
    "display(JS_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Calculate the Voronoi cells for the pumps, and count the number of deaths falling into each of the cells.  Create a bar chart of the number of deaths in each cell. Pinpoint the possible source of the infection.\n",
    "\n",
    "*Store the Voronoi cells in a GeoDataFrame, then you can easily do a spatial join (e.g. testing whether a polygon in the Voronoi dataframe contains a point from the death dataframe).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d = deaths.lat_proj_rs.values\n",
    "Y_d = deaths.long_proj_rs.values\n",
    "\n",
    "X_p = pumps.lat_proj_rs.values\n",
    "Y_p = pumps.long_proj_rs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spatial bounds of available data\n",
    "min_x = np.min(np.concatenate((X_d, X_p)))\n",
    "max_x = np.max(np.concatenate((X_d, X_p)))\n",
    "min_y = np.min(np.concatenate((Y_d, Y_p)))\n",
    "max_y = np.max(np.concatenate((Y_d, Y_p)))\n",
    "\n",
    "# Calculate spatial size of data\n",
    "size_x = max_x - min_x\n",
    "size_y = max_y - min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Voronoi cells using scipy's built-in function\n",
    "vor = scipy.spatial.Voronoi(np.vstack([X_p, Y_p]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Voronoi cells\n",
    "nrows = 1\n",
    "ncols = 1\n",
    "f_size = 11\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*f_size, nrows*f_size*size_y/size_x))\n",
    "\n",
    "axislabelsize = 20\n",
    "axisticksize = 15\n",
    "axislegendsize = 15\n",
    "s_radius = 20\n",
    "\n",
    "# Scipy's built-in Voronoi cell visualizator\n",
    "scipy.spatial.voronoi_plot_2d(vor, point_size=s_radius, ax=axes)\n",
    "\n",
    "# Annotate pumps\n",
    "for _, p in pumps.iterrows():\n",
    "    axes.annotate('Pump #{0}'.format(p.OBJECTID),\n",
    "                  xy=(p.lat_proj_rs, p.long_proj_rs), xycoords='data',\n",
    "                  xytext=(-28, 30), textcoords='offset points', size='14',\n",
    "                  arrowprops=dict(arrowstyle='-', color='black', alpha=0.6))\n",
    "\n",
    "axes.set_xlabel('Meters from center (Lat.) [m]', fontsize=axislabelsize)\n",
    "axes.set_ylabel('Meters from center (Long.) [m]', fontsize=axislabelsize)\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "# Set border limits\n",
    "mult = 1.35\n",
    "axes.set_xlim(mult*min_x, mult*max_x)\n",
    "axes.set_ylim(mult*min_y, mult*max_y)\n",
    "\n",
    "# Create figure legend\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Pumps', markerfacecolor='C0', markersize=s_radius),\n",
    "    Line2D([0], [0], marker='o', color='w', label='Voronoi vertices', markerfacecolor='orange', markersize=12)\n",
    "]\n",
    "axes.legend(handles=handles, loc='upper right', fontsize=axislegendsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding death count in Voronoi cells\n",
    "\n",
    "Now we need to count all deaths in each Voronoi cells to create a meaningful visualization, which could be use then to pinpoint the source of the epidemic.\n",
    "\n",
    "For an initial visualization, here I'll use the `cKDTree` method from the `scipy` library. The reason for this, that Voronoi cells of pumps are simply just the collection of points, which are nearest to a given pump. This interpretation makes the problem a lot easier, since it tell us that finding the number of deaths in a Voronoi cell is equivalent to the problem of finding the pumps nearest to the location of deaths and then counting all the neigbouring points of pumps thus obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the KD-Tree for the pumps\n",
    "voronoi_kdtree = scipy.spatial.cKDTree(np.vstack([X_p, Y_p]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the closest pump neighbour of deaths\n",
    "closest_pump_dist, closest_pump_regions = voronoi_kdtree.query(np.vstack([X_d, Y_d]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose distinct colors for the deaths in different\n",
    "# Voronoi cells from a colormap\n",
    "def choose_color(regions, cmap=cm.jet_r):\n",
    "    region_idx = np.unique(regions)\n",
    "    m = scipy.interpolate.interp1d([min(region_idx), max(region_idx)], [0,1])\n",
    "    \n",
    "    colors = {r: cmap(m(r)) for r in region_idx}\n",
    "    \n",
    "    colors_arr = []\n",
    "    for d in regions:\n",
    "        colors_arr.append(colors[d])\n",
    "        \n",
    "    return np.array(colors_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Voronoi cells\n",
    "nrows = 1\n",
    "ncols = 1\n",
    "f_size = 11\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*f_size, nrows*f_size*size_y/size_x))\n",
    "\n",
    "axislabelsize = 20\n",
    "axisticksize = 15\n",
    "axislegendsize = 15\n",
    "s_p_radius = 20\n",
    "s_d_radius = 7\n",
    "\n",
    "axes.scatter(X_d, Y_d,\n",
    "             c=choose_color(closest_pump_regions), marker='x', s=s_d_radius**2)\n",
    "\n",
    "# Scipy's built-in Voronoi cell visualizator\n",
    "scipy.spatial.voronoi_plot_2d(vor, point_size=s_p_radius, ax=axes)\n",
    "\n",
    "# Annotate pumps\n",
    "for _, p in pumps.iterrows():\n",
    "    axes.annotate('Pump #{0}'.format(p.OBJECTID),\n",
    "                  xy=(p.lat_proj_rs, p.long_proj_rs), xycoords='data',\n",
    "                  xytext=(-28, 30), textcoords='offset points', size='14',\n",
    "                  arrowprops=dict(arrowstyle='-', color='black', alpha=0.6))\n",
    "\n",
    "axes.set_xlabel('Meters from center (Lat.) [m]', fontsize=axislabelsize)\n",
    "axes.set_ylabel('Meters from center (Long.) [m]', fontsize=axislabelsize)\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "# Set border limits\n",
    "mult = 1.35\n",
    "axes.set_xlim(mult*min_x, mult*max_x)\n",
    "axes.set_ylim(mult*min_y, mult*max_y)\n",
    "\n",
    "# Create figure legend\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Pumps', markerfacecolor='C0', markersize=s_p_radius),\n",
    "    Line2D([0], [0], marker='.', color='w', label='Voronoi vertices', markerfacecolor='orange', markersize=16),\n",
    "    Line2D([0], [0], marker='X', color='w', label='Deaths', markerfacecolor='tab:red', markersize=16, lw=1)\n",
    "]\n",
    "axes.legend(handles=handles, loc='upper right', fontsize=axislegendsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly the `cKDTree` method is unable to label regions correctly, and can't handle the case when there are Voronoi cells without test points. To create a usable dataset beyond a good-looking visualization, we have to use some point-in-polygon searching algorithm to identify and count deaths in the corresponding Voronoi cells.\n",
    "\n",
    "Since some of the Voronoi cells are \"unbounded/infinte polygons\" - polygons with missing edges, we need to turn them first into \"real/finite polygons\". Using a function from GitHub at we can create these missing edges. (Source: https://gist.github.com/pv/8036995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voronoi_finite_polygons_2d(vor, radius=None):\n",
    "    \"\"\"\n",
    "    Reconstruct infinite voronoi regions in a 2D diagram to finite\n",
    "    regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vor : Voronoi\n",
    "        Input diagram\n",
    "    radius : float, optional\n",
    "        Distance to 'points at infinity'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    regions : list of tuples\n",
    "        Indices of vertices in each revised Voronoi regions.\n",
    "    vertices : list of tuples\n",
    "        Coordinates for revised Voronoi vertices. Same as coordinates\n",
    "        of input vertices, with 'points at infinity' appended to the\n",
    "        end.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if vor.points.shape[1] != 2:\n",
    "        raise ValueError(\"Requires 2D input\")\n",
    "\n",
    "    new_regions = []\n",
    "    new_vertices = vor.vertices.tolist()\n",
    "\n",
    "    center = vor.points.mean(axis=0)\n",
    "    if radius is None:\n",
    "        radius = vor.points.ptp().max()\n",
    "\n",
    "    # Construct a map containing all ridges for a given point\n",
    "    all_ridges = {}\n",
    "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
    "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
    "\n",
    "    # Reconstruct infinite regions\n",
    "    for p1, region in enumerate(vor.point_region):\n",
    "        vertices = vor.regions[region]\n",
    "\n",
    "        if all(v >= 0 for v in vertices):\n",
    "            # finite region\n",
    "            new_regions.append(vertices)\n",
    "            continue\n",
    "\n",
    "        # reconstruct a non-finite region\n",
    "        ridges = all_ridges[p1]\n",
    "        new_region = [v for v in vertices if v >= 0]\n",
    "\n",
    "        for p2, v1, v2 in ridges:\n",
    "            if v2 < 0:\n",
    "                v1, v2 = v2, v1\n",
    "            if v1 >= 0:\n",
    "                # finite ridge: already in the region\n",
    "                continue\n",
    "\n",
    "            # Compute the missing endpoint of an infinite ridge\n",
    "\n",
    "            t = vor.points[p2] - vor.points[p1] # tangent\n",
    "            t /= np.linalg.norm(t)\n",
    "            n = np.array([-t[1], t[0]])  # normal\n",
    "\n",
    "            midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
    "            direction = np.sign(np.dot(midpoint - center, n)) * n\n",
    "            far_point = vor.vertices[v2] + direction * radius\n",
    "\n",
    "            new_region.append(len(new_vertices))\n",
    "            new_vertices.append(far_point.tolist())\n",
    "\n",
    "        # sort region counterclockwise\n",
    "        vs = np.asarray([new_vertices[v] for v in new_region])\n",
    "        c = vs.mean(axis=0)\n",
    "        angles = np.arctan2(vs[:,1] - c[1], vs[:,0] - c[0])\n",
    "        new_region = np.array(new_region)[np.argsort(angles)]\n",
    "\n",
    "        # finish\n",
    "        new_regions.append(new_region.tolist())\n",
    "\n",
    "    return new_regions, np.asarray(new_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_regions, finite_vertices = voronoi_finite_polygons_2d(vor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can recreate scipy's Voronoi cell visualizator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Voronoi cells\n",
    "nrows = 1\n",
    "ncols = 1\n",
    "f_size = 11\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*f_size, nrows*f_size*size_y/size_x))\n",
    "\n",
    "axislabelsize = 20\n",
    "axisticksize = 15\n",
    "axislegendsize = 15\n",
    "s_v_radius = 7\n",
    "s_p_radius = 16\n",
    "s_d_radius = 7\n",
    "\n",
    "# Color Voronoi cells\n",
    "for idx, region in enumerate(finite_regions):\n",
    "    polygon = finite_vertices[region]\n",
    "    plt.fill(*zip(*polygon), color=colors[idx], alpha=0.2)\n",
    "\n",
    "# Mark cell vertices\n",
    "axes.scatter(finite_vertices[:,0], finite_vertices[:,1],\n",
    "             c='tab:orange', s=s_v_radius**2, alpha=0.6, zorder=3)\n",
    "\n",
    "# Mark pumps\n",
    "axes.scatter(X_p, Y_p,\n",
    "             c='C0', s=s_p_radius**2, alpha=0.8, zorder=3)\n",
    "\n",
    "# Mark deaths\n",
    "axes.scatter(X_d, Y_d,\n",
    "             c=choose_color(closest_pump_regions), marker='x', s=s_d_radius**2, zorder=2)\n",
    "\n",
    "# Annotate pumps\n",
    "for _, p in pumps.iterrows():\n",
    "    axes.annotate('Pump #{0}'.format(p.OBJECTID),\n",
    "                  xy=(p.lat_proj_rs, p.long_proj_rs), xycoords='data',\n",
    "                  xytext=(-28, 30), textcoords='offset points', size='14',\n",
    "                  arrowprops=dict(arrowstyle='-', color='black', alpha=0.6))\n",
    "\n",
    "axes.set_xlabel('Meters from center (Lat.) [m]', fontsize=axislabelsize)\n",
    "axes.set_ylabel('Meters from center (Long.) [m]', fontsize=axislabelsize)\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "# Set border limits\n",
    "mult = 1.35\n",
    "axes.set_xlim(mult*min_x, mult*max_x)\n",
    "axes.set_ylim(mult*min_y, mult*max_y)\n",
    "\n",
    "# Create figure legend\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Pumps', markerfacecolor='C0', markersize=s_p_radius),\n",
    "    Line2D([0], [0], marker='.', color='w', label='Voronoi vertices', markerfacecolor='orange', markersize=16),\n",
    "    Line2D([0], [0], marker='X', color='w', label='Deaths', markerfacecolor='tab:red', markersize=16, lw=1)\n",
    "]\n",
    "axes.legend(handles=handles, loc='upper right', fontsize=axislegendsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a point-in-polygon searching algorithm and simply count the number of deaths in the finite polygons created above above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the counter for each pumps\n",
    "deaths_near_pumps = {i+1: 0 for i in range(len(pumps))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_coords = np.vstack([X_d, Y_d]).T\n",
    "\n",
    "# Loop through regions and count how many deaths are in them\n",
    "for idx, r in enumerate(finite_regions):\n",
    "    # Handle the current Voronoi cell as a shapely Polygon\n",
    "    polygon = Polygon([finite_vertices[v] for v in r])\n",
    "    for d in death_coords:\n",
    "        # Handle the location of the current death as a shapely Point\n",
    "        point = Point(d)\n",
    "        \n",
    "        # If the polygon cointains the point, increment the counter\n",
    "        # of the current pump/cell\n",
    "        if polygon.contains(point):\n",
    "            deaths_near_pumps[idx+1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# death_near_pumps_arr\n",
    "dnp_arr = np.array(list(deaths_near_pumps.items())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*11, nrows*7))\n",
    "\n",
    "axislabelsize = 20\n",
    "axisticksize = 15\n",
    "\n",
    "# One normal and one log scaled axis\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "for i in range(ncols):\n",
    "    axes[i].bar(dnp_arr[0], dnp_arr[1], color=colors)\n",
    "\n",
    "    plt.sca(axes[i])\n",
    "    plt.xticks(dnp_arr[0], dnp_arr[0])\n",
    "\n",
    "    axes[i].set_xlabel('Pumps', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('Number of deaths nearby', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Create a death density map using 2D Kernel Density Estimation. Display the density and its contours on the map along with the pumps. What is the density value at each of the pumps? Pinpoint the possible source of the infection.\n",
    "\n",
    "*Use the projected Cartesian coordinate system for this exercise.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "f_size = 11\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*f_size, nrows*f_size*size_y/size_x))\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "axislabelsize = 20\n",
    "axisticksize = 15\n",
    "s_radius= 10\n",
    "\n",
    "# KDE plot of deaths\n",
    "sns.kdeplot(X_d, Y_d, bw='scott',\n",
    "            shade=True, shade_lowest=False,\n",
    "            n_levels=15, cmap='Purples_r',\n",
    "            ax=axes[0], zorder=1)\n",
    "\n",
    "sns.kdeplot(X_d, Y_d,  bw='scott',\n",
    "            n_levels=15, cmap='Purples_r',\n",
    "            ax=axes[1], zorder=1)\n",
    "\n",
    "for i in range(ncols):\n",
    "    # Mark pump locations\n",
    "    axes[i].scatter(X_p, Y_p, label='Pumps',\n",
    "                    c='C0', marker='o', lw=5, s=s_radius**2, alpha=0.8)\n",
    "    \n",
    "    \n",
    "    for _, p in pumps.iterrows():\n",
    "        axes[i].annotate('Pump #{0}'.format(p.OBJECTID),\n",
    "                         xy=(p.lat_proj_rs, p.long_proj_rs), xycoords='data',\n",
    "                         xytext=(-28, 30), textcoords='offset points', size='14',\n",
    "                         arrowprops=dict(arrowstyle='-', color='black', alpha=0.6))\n",
    "    \n",
    "    axes[i].set_xlabel('Meters from center (Lat.) [m]', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('Meters from center (Long.) [m]', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "    \n",
    "    axes[i].set_xlim(min_x*1.2, max_x*1.2)\n",
    "    axes[i].set_ylim(min_y*1.2, max_y*1.2)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the look of these density plots, Pump #7 is pretty suspicious... To further investigate, calculate the density values at the locations of the pumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_d = np.vstack([X_d, Y_d])\n",
    "XY_p = np.vstack([X_p, Y_p])\n",
    "\n",
    "# Gaussian KDE by choosing bandwith with Scott's method\n",
    "kernel = scipy.stats.gaussian_kde(dataset=XY_d, bw_method='scott')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize probabilities for the next estimation\n",
    "norm = np.sum(kernel(XY_p))\n",
    "\n",
    "# Estimate probabilities of pumps being dangerous\n",
    "for idx, xy in enumerate(XY_p.T):\n",
    "    print(('Probability of poisoning of Pump #{0} is ' + b_on + 'P = {1:.4f} %' + b_off).format(idx+1,\n",
    "                                                                                                kernel(xy)[0]/norm * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this analysis, clearly Pump #7 is the most probable main source of the outbreak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "\n",
    "Create a GeoJSON object from the Voronoi cells, put the cells on the map, colored according to the number of deaths (like on a heatmap). Display the results in the notebook.\n",
    "\n",
    "*[GeoJSON](http://geojson.org/) is a common format that is used in web applications. It is basically a simple key-value dictionary with a predefined structure for storing geographic information. Once loaded into Python, it behaves like a normal Python dictionary, thus creating or modifying it is quite straightforward. When reading or writing to a file, the `json` module is handy. The advice is to write a function that converts a list of coordinates from a polygon into a GeoJSON feature, then add it to your GeoJSON structure.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "(optional)\n",
    "Download the street network of the area of the deaths from OpenStreetMap using its [map API](https://wiki.openstreetmap.org/wiki/API_v0.6#Retrieving_map_data_by_bounding_box:_GET_.2Fapi.2F0.6.2Fmap). Use street segments given back by the API as edges of a street graph. Develop a method based on the cholera dataset to classify these edges into three categories:\n",
    "* existed at the time of John Snow\n",
    "* did not exist at the time of John Snow\n",
    "* cannot decide\n",
    "\n",
    "*You'll get the id of each node and way that falls within a bounding box with the GET method of the map API. Use the ids to retrieve the shapes with the help of the ways API.*\n",
    "\n",
    "*The results will be in XML format. Find a good [XML parser](https://docs.python.org/2/library/xml.etree.elementtree.html#module-xml.etree.ElementTree) to navigate the structures.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9\n",
    "(optional)\n",
    "\n",
    "Plot the streets on the map along with the pumps and the deaths colored by the results of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
